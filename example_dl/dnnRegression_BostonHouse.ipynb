{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b17e2f3",
   "metadata": {},
   "source": [
    "+ [download dataset](https://www.kaggle.com/code/prasadperera/the-boston-housing-dataset/data)\n",
    "+ items:\n",
    "    + CRIM - per capita crime rate by town\n",
    "    + ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "    + INDUS - proportion of non-retail business acres per town.\n",
    "    + CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "    + NOX - nitric oxides concentration (parts per 10 million)\n",
    "    + RM - average number of rooms per dwelling\n",
    "    + AGE - proportion of owner-occupied units built prior to 1940\n",
    "    + DIS - weighted distances to five Boston employment centres\n",
    "    + RAD - index of accessibility to radial highways\n",
    "    + TAX - full-value property-tax rate per \\$10,000\n",
    "    + PTRATIO - pupil-teacher ratio by town\n",
    "    + B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "    + LSTAT - % lower status of the population\n",
    "    + MEDV - Median value of owner-occupied homes in $1000's\n",
    "+ 14 inputs -> 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f18ba282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, math, time, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c117857",
   "metadata": {},
   "source": [
    "### Observation and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9dbb18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.00632  18.00   2.310  0  0.5380  6.5750  65.20  4.0900   1  296.0  15.30 396.90   4.98  24.00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02731   0.00   7.070  0  0.4690  6.4210  78...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02729   0.00   7.070  0  0.4690  7.1850  61...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03237   0.00   2.180  0  0.4580  6.9980  45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.06905   0.00   2.180  0  0.4580  7.1470  54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02985   0.00   2.180  0  0.4580  6.4300  58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.06263   0.00  11.930  0  0.5730  6.5930  69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.04527   0.00  11.930  0  0.5730  6.1200  76...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.06076   0.00  11.930  0  0.5730  6.9760  91...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.10959   0.00  11.930  0  0.5730  6.7940  89...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.04741   0.00  11.930  0  0.5730  6.0300  80...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.00632  18.00   2.310  0  0.5380  6.5750  65.20  4.0900   1  296.0  15.30 396.90   4.98  24.00\n",
       "0     0.02731   0.00   7.070  0  0.4690  6.4210  78...                                              \n",
       "1     0.02729   0.00   7.070  0  0.4690  7.1850  61...                                              \n",
       "2     0.03237   0.00   2.180  0  0.4580  6.9980  45...                                              \n",
       "3     0.06905   0.00   2.180  0  0.4580  7.1470  54...                                              \n",
       "4     0.02985   0.00   2.180  0  0.4580  6.4300  58...                                              \n",
       "..                                                 ...                                              \n",
       "500   0.06263   0.00  11.930  0  0.5730  6.5930  69...                                              \n",
       "501   0.04527   0.00  11.930  0  0.5730  6.1200  76...                                              \n",
       "502   0.06076   0.00  11.930  0  0.5730  6.9760  91...                                              \n",
       "503   0.10959   0.00  11.930  0  0.5730  6.7940  89...                                              \n",
       "504   0.04741   0.00  11.930  0  0.5730  6.0300  80...                                              \n",
       "\n",
       "[505 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./housing.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e2cdada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1      2    3      4      5     6       7    8      9     10  \\\n",
       "0    0.00632  18.0   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
       "1    0.02731   0.0   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
       "2    0.02729   0.0   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
       "3    0.03237   0.0   2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
       "4    0.06905   0.0   2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
       "..       ...   ...    ...  ...    ...    ...   ...     ...  ...    ...   ...   \n",
       "501  0.06263   0.0  11.93  0.0  0.573  6.593  69.1  2.4786  1.0  273.0  21.0   \n",
       "502  0.04527   0.0  11.93  0.0  0.573  6.120  76.7  2.2875  1.0  273.0  21.0   \n",
       "503  0.06076   0.0  11.93  0.0  0.573  6.976  91.0  2.1675  1.0  273.0  21.0   \n",
       "504  0.10959   0.0  11.93  0.0  0.573  6.794  89.3  2.3889  1.0  273.0  21.0   \n",
       "505  0.04741   0.0  11.93  0.0  0.573  6.030  80.8  2.5050  1.0  273.0  21.0   \n",
       "\n",
       "         11    12    13  \n",
       "0    396.90  4.98  24.0  \n",
       "1    396.90  9.14  21.6  \n",
       "2    392.83  4.03  34.7  \n",
       "3    394.63  2.94  33.4  \n",
       "4    396.90  5.33  36.2  \n",
       "..      ...   ...   ...  \n",
       "501  391.99  9.67  22.4  \n",
       "502  396.90  9.08  20.6  \n",
       "503  396.90  5.64  23.9  \n",
       "504  393.45  6.48  22.0  \n",
       "505  396.90  7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "with open(\"./housing.csv\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        L = list(filter(lambda s:s, line.split(\" \")))\n",
    "        L = list(map(lambda s:float(s.replace('\\n','')),L))\n",
    "        assert len(L)==14\n",
    "        data.append(L)\n",
    "data = pd.DataFrame(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a495cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "               12          13  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbce128d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "499\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1      2    3      4      5     6       7    8      9     10  \\\n",
       "0    0.00632  18.0   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
       "1    0.02731   0.0   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
       "2    0.02729   0.0   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
       "3    0.03237   0.0   2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
       "4    0.06905   0.0   2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
       "..       ...   ...    ...  ...    ...    ...   ...     ...  ...    ...   ...   \n",
       "494  0.06263   0.0  11.93  0.0  0.573  6.593  69.1  2.4786  1.0  273.0  21.0   \n",
       "495  0.04527   0.0  11.93  0.0  0.573  6.120  76.7  2.2875  1.0  273.0  21.0   \n",
       "496  0.06076   0.0  11.93  0.0  0.573  6.976  91.0  2.1675  1.0  273.0  21.0   \n",
       "497  0.10959   0.0  11.93  0.0  0.573  6.794  89.3  2.3889  1.0  273.0  21.0   \n",
       "498  0.04741   0.0  11.93  0.0  0.573  6.030  80.8  2.5050  1.0  273.0  21.0   \n",
       "\n",
       "         11    12    13  \n",
       "0    396.90  4.98  24.0  \n",
       "1    396.90  9.14  21.6  \n",
       "2    392.83  4.03  34.7  \n",
       "3    394.63  2.94  33.4  \n",
       "4    396.90  5.33  36.2  \n",
       "..      ...   ...   ...  \n",
       "494  391.99  9.67  22.4  \n",
       "495  396.90  9.08  20.6  \n",
       "496  396.90  5.64  23.9  \n",
       "497  393.45  6.48  22.0  \n",
       "498  396.90  7.88  11.9  \n",
       "\n",
       "[499 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = data.describe()\n",
    "outliers = []\n",
    "series = pd.Series([True]*len(data))\n",
    "for i in range(len(data.columns)):\n",
    "    seriesi = abs(data[0]-ds[0]['mean'])/ds[0]['std'] < 4\n",
    "    outliers.append( len(data) - seriesi.sum() )\n",
    "    series = series & seriesi\n",
    "print(outliers)\n",
    "print(series.sum())\n",
    "data1 = data[series].reset_index(drop=True)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ce395d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.534426</td>\n",
       "      <td>0.276243</td>\n",
       "      <td>-1.272797</td>\n",
       "      <td>-0.274372</td>\n",
       "      <td>-0.129757</td>\n",
       "      <td>0.403283</td>\n",
       "      <td>-0.105890</td>\n",
       "      <td>0.125226</td>\n",
       "      <td>-0.970902</td>\n",
       "      <td>-0.650800</td>\n",
       "      <td>-1.442795</td>\n",
       "      <td>0.435186</td>\n",
       "      <td>-1.073789</td>\n",
       "      <td>0.139621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.530479</td>\n",
       "      <td>-0.491460</td>\n",
       "      <td>-0.578738</td>\n",
       "      <td>-0.274372</td>\n",
       "      <td>-0.725868</td>\n",
       "      <td>0.183129</td>\n",
       "      <td>0.380991</td>\n",
       "      <td>0.542237</td>\n",
       "      <td>-0.854581</td>\n",
       "      <td>-0.974339</td>\n",
       "      <td>-0.290794</td>\n",
       "      <td>0.435186</td>\n",
       "      <td>-0.479632</td>\n",
       "      <td>-0.124076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.530483</td>\n",
       "      <td>-0.491460</td>\n",
       "      <td>-0.578738</td>\n",
       "      <td>-0.274372</td>\n",
       "      <td>-0.725868</td>\n",
       "      <td>1.275323</td>\n",
       "      <td>-0.251599</td>\n",
       "      <td>0.542237</td>\n",
       "      <td>-0.854581</td>\n",
       "      <td>-0.974339</td>\n",
       "      <td>-0.290794</td>\n",
       "      <td>0.389133</td>\n",
       "      <td>-1.209474</td>\n",
       "      <td>1.315273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.529527</td>\n",
       "      <td>-0.491460</td>\n",
       "      <td>-1.291753</td>\n",
       "      <td>-0.274372</td>\n",
       "      <td>-0.820900</td>\n",
       "      <td>1.007993</td>\n",
       "      <td>-0.795342</td>\n",
       "      <td>1.062894</td>\n",
       "      <td>-0.738259</td>\n",
       "      <td>-1.094168</td>\n",
       "      <td>0.123927</td>\n",
       "      <td>0.409501</td>\n",
       "      <td>-1.365154</td>\n",
       "      <td>1.172436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.522630</td>\n",
       "      <td>-0.491460</td>\n",
       "      <td>-1.291753</td>\n",
       "      <td>-0.274372</td>\n",
       "      <td>-0.820900</td>\n",
       "      <td>1.220999</td>\n",
       "      <td>-0.496816</td>\n",
       "      <td>1.062894</td>\n",
       "      <td>-0.738259</td>\n",
       "      <td>-1.094168</td>\n",
       "      <td>0.123927</td>\n",
       "      <td>0.435186</td>\n",
       "      <td>-1.023800</td>\n",
       "      <td>1.480084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>-0.523837</td>\n",
       "      <td>-0.491460</td>\n",
       "      <td>0.129903</td>\n",
       "      <td>-0.274372</td>\n",
       "      <td>0.172618</td>\n",
       "      <td>0.429015</td>\n",
       "      <td>0.032711</td>\n",
       "      <td>-0.640902</td>\n",
       "      <td>-0.970902</td>\n",
       "      <td>-0.788604</td>\n",
       "      <td>1.183768</td>\n",
       "      <td>0.379628</td>\n",
       "      <td>-0.403935</td>\n",
       "      <td>-0.036177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>-0.527101</td>\n",
       "      <td>-0.491460</td>\n",
       "      <td>0.129903</td>\n",
       "      <td>-0.274372</td>\n",
       "      <td>0.172618</td>\n",
       "      <td>-0.247173</td>\n",
       "      <td>0.302806</td>\n",
       "      <td>-0.731759</td>\n",
       "      <td>-0.970902</td>\n",
       "      <td>-0.788604</td>\n",
       "      <td>1.183768</td>\n",
       "      <td>0.435186</td>\n",
       "      <td>-0.488202</td>\n",
       "      <td>-0.233950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>-0.524188</td>\n",
       "      <td>-0.491460</td>\n",
       "      <td>0.129903</td>\n",
       "      <td>-0.274372</td>\n",
       "      <td>0.172618</td>\n",
       "      <td>0.976542</td>\n",
       "      <td>0.811010</td>\n",
       "      <td>-0.788812</td>\n",
       "      <td>-0.970902</td>\n",
       "      <td>-0.788604</td>\n",
       "      <td>1.183768</td>\n",
       "      <td>0.435186</td>\n",
       "      <td>-0.979524</td>\n",
       "      <td>0.128634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-0.515006</td>\n",
       "      <td>-0.491460</td>\n",
       "      <td>0.129903</td>\n",
       "      <td>-0.274372</td>\n",
       "      <td>0.172618</td>\n",
       "      <td>0.716360</td>\n",
       "      <td>0.750594</td>\n",
       "      <td>-0.683549</td>\n",
       "      <td>-0.970902</td>\n",
       "      <td>-0.788604</td>\n",
       "      <td>1.183768</td>\n",
       "      <td>0.396149</td>\n",
       "      <td>-0.859550</td>\n",
       "      <td>-0.080127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>-0.526699</td>\n",
       "      <td>-0.491460</td>\n",
       "      <td>0.129903</td>\n",
       "      <td>-0.274372</td>\n",
       "      <td>0.172618</td>\n",
       "      <td>-0.375835</td>\n",
       "      <td>0.448515</td>\n",
       "      <td>-0.628350</td>\n",
       "      <td>-0.970902</td>\n",
       "      <td>-0.788604</td>\n",
       "      <td>1.183768</td>\n",
       "      <td>0.435186</td>\n",
       "      <td>-0.659593</td>\n",
       "      <td>-1.189853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0   -0.534426  0.276243 -1.272797 -0.274372 -0.129757  0.403283 -0.105890   \n",
       "1   -0.530479 -0.491460 -0.578738 -0.274372 -0.725868  0.183129  0.380991   \n",
       "2   -0.530483 -0.491460 -0.578738 -0.274372 -0.725868  1.275323 -0.251599   \n",
       "3   -0.529527 -0.491460 -1.291753 -0.274372 -0.820900  1.007993 -0.795342   \n",
       "4   -0.522630 -0.491460 -1.291753 -0.274372 -0.820900  1.220999 -0.496816   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "494 -0.523837 -0.491460  0.129903 -0.274372  0.172618  0.429015  0.032711   \n",
       "495 -0.527101 -0.491460  0.129903 -0.274372  0.172618 -0.247173  0.302806   \n",
       "496 -0.524188 -0.491460  0.129903 -0.274372  0.172618  0.976542  0.811010   \n",
       "497 -0.515006 -0.491460  0.129903 -0.274372  0.172618  0.716360  0.750594   \n",
       "498 -0.526699 -0.491460  0.129903 -0.274372  0.172618 -0.375835  0.448515   \n",
       "\n",
       "           7         8         9         10        11        12        13  \n",
       "0    0.125226 -0.970902 -0.650800 -1.442795  0.435186 -1.073789  0.139621  \n",
       "1    0.542237 -0.854581 -0.974339 -0.290794  0.435186 -0.479632 -0.124076  \n",
       "2    0.542237 -0.854581 -0.974339 -0.290794  0.389133 -1.209474  1.315273  \n",
       "3    1.062894 -0.738259 -1.094168  0.123927  0.409501 -1.365154  1.172436  \n",
       "4    1.062894 -0.738259 -1.094168  0.123927  0.435186 -1.023800  1.480084  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "494 -0.640902 -0.970902 -0.788604  1.183768  0.379628 -0.403935 -0.036177  \n",
       "495 -0.731759 -0.970902 -0.788604  1.183768  0.435186 -0.488202 -0.233950  \n",
       "496 -0.788812 -0.970902 -0.788604  1.183768  0.435186 -0.979524  0.128634  \n",
       "497 -0.683549 -0.970902 -0.788604  1.183768  0.396149 -0.859550 -0.080127  \n",
       "498 -0.628350 -0.970902 -0.788604  1.183768  0.435186 -0.659593 -1.189853  \n",
       "\n",
       "[499 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means, stds = data1.mean(axis=0), data1.std(axis=0)\n",
    "data1 = (data1-means)/stds\n",
    "data1 #.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f002b642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 14) (100, 14)\n",
      "(399, 13) (399, 1) (100, 13) (100, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.51984257, -0.49145965,  0.26113296, -0.27437177, -1.00232487,\n",
       "        -0.59884815, -1.12229842,  0.3213938 , -0.50561522, -0.03967092,\n",
       "         0.12392668,  0.4256814 , -0.48534537]),\n",
       " array([-0.26691222]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = list(range(len(data1)))\n",
    "random.shuffle(R)\n",
    "\n",
    "dataTrain, dataVal = data1.loc[R[:int(len(R)*0.8)]], data1.loc[R[int(len(R)*0.8):]]\n",
    "print(dataTrain.shape, dataVal.shape)\n",
    "xTrain, yTrain = np.array(dataTrain[ list(dataTrain.columns)[:13] ]), np.array(dataTrain[[13]])\n",
    "xVal, yVal = np.array(dataVal[ list(dataVal.columns)[:13] ]), np.array(dataVal[[13]])\n",
    "print(xTrain.shape, yTrain.shape, xVal.shape, yVal.shape)\n",
    "xTrain[0], yTrain[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9e104b",
   "metadata": {},
   "source": [
    "### Dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91fb8283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-0.5198, -0.4915,  0.2611, -0.2744, -1.0023, -0.5988, -1.1223,  0.3214,\n",
      "        -0.5056, -0.0397,  0.1239,  0.4257, -0.4853], device='cuda:0'), tensor([-0.2669], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "        assert len(self.X), len(self.y)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, index):\n",
    "        x = torch.Tensor(self.X[index]).to('cuda')\n",
    "        y = torch.Tensor(self.y[index]).to('cuda')\n",
    "        return x,y\n",
    "    \n",
    "trainDataset = MyDataset(xTrain, yTrain)\n",
    "valDataset = MyDataset(xVal, yVal)\n",
    "print(trainDataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48c08f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 7\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "trainDataLoader = DataLoader(trainDataset, batch_size=batch_size, pin_memory=False)\n",
    "valDataLoader = DataLoader(valDataset, batch_size=batch_size, pin_memory=False)\n",
    "# stepPerEpoch = len(trainDataLoader)\n",
    "print( len(trainDataLoader), len(valDataLoader) ) # 399/16=24 # 100/16=6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ad1c1b",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9386dc12",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (dense1): Linear(in_features=13, out_features=64, bias=True)\n",
      "  (dense2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (dense3): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "[('dense1.weight', torch.Size([64, 13]), 832), ('dense1.bias', torch.Size([64]), 64), ('dense2.weight', torch.Size([64, 64]), 4096), ('dense2.bias', torch.Size([64]), 64), ('dense3.weight', torch.Size([1, 64]), 64), ('dense3.bias', torch.Size([1]), 1)]\n",
      "[('dense1.weight', torch.Size([64, 13]), 832), ('dense1.bias', torch.Size([64]), 64), ('dense2.weight', torch.Size([64, 64]), 4096), ('dense2.bias', torch.Size([64]), 64), ('dense3.weight', torch.Size([1, 64]), 64), ('dense3.bias', torch.Size([1]), 1)]\n",
      "0.00023 tensor([[-0.2190],\n",
      "        [-0.1828]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1  = nn.Linear(13, 64)\n",
    "        self.dense2  = nn.Linear(64, 64)\n",
    "        self.dense3  = nn.Linear(64, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "\n",
    "model = MyModel().to('cuda')\n",
    "print( model )\n",
    "\n",
    "D = model.state_dict()\n",
    "print( [(name,D[name].shape,D[name].numel()) for name in D] )\n",
    "P = model.named_parameters()\n",
    "print( [(name,weight.shape,weight.numel()) for name,weight in P] )\n",
    "\n",
    "with torch.no_grad():\n",
    "    testInput = torch.rand(2,13).to('cuda')\n",
    "    start = time.time()\n",
    "    pred = model(testInput)\n",
    "    print( round(time.time()-start,5), pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1528d2f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.0929], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print( list(model.named_parameters())[-1][1] ) # last layer # weight # every time will different\n",
    "torch.save({'model_state_dict':model.state_dict(),'epoch':0,'loss':99}, 'init.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0371804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.0561], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0929], device='cuda:0', requires_grad=True) 0 99\n"
     ]
    }
   ],
   "source": [
    "model = MyModel().to('cuda')\n",
    "print( list(model.named_parameters())[-1][1] )\n",
    "\n",
    "checkpoint = torch.load('./init.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "print( list(model.named_parameters())[-1][1], epoch, loss )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092da9f4",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "774871f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be50c87",
   "metadata": {},
   "source": [
    "### Loss / Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20bd7c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6667)\n"
     ]
    }
   ],
   "source": [
    "lossFunc = nn.MSELoss()\n",
    "yReal = torch.Tensor([[0,1,2],[3,4,5]])\n",
    "yPred = torch.Tensor([[0,1,2],[3,4,3]])\n",
    "\n",
    "#loss = lossFunc(xReal, xPred) # (5-3)**2/6\n",
    "def myLoss(yReal, yPred):\n",
    "    return torch.square(yReal-yPred).sum()/(xReal.shape[0]*yReal.shape[1])\n",
    "loss = myLoss(yReal, yPred)\n",
    "print( loss )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299e13a7",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecf437ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100\n",
      "batch=7/7, valLoss=0.037965874\n",
      "Epoch: 2/100\n",
      "batch=7/7, valLoss=0.033571478\n",
      "Epoch: 3/100\n",
      "batch=7/7, valLoss=0.030449013\n",
      "Epoch: 4/100\n",
      "batch=7/7, valLoss=0.028047314\n",
      "Epoch: 5/100\n",
      "batch=7/7, valLoss=0.026276088\n",
      "Epoch: 6/100\n",
      "batch=7/7, valLoss=0.025025229\n",
      "Epoch: 7/100\n",
      "batch=7/7, valLoss=0.024164646\n",
      "Epoch: 8/100\n",
      "batch=7/7, valLoss=0.023584258\n",
      "Epoch: 9/100\n",
      "batch=7/7, valLoss=0.023184002\n",
      "Epoch: 10/100\n",
      "batch=7/7, valLoss=0.022903830\n",
      "Epoch: 11/100\n",
      "batch=7/7, valLoss=0.022703713\n",
      "Epoch: 12/100\n",
      "batch=7/7, valLoss=0.022563629\n",
      "Epoch: 13/100\n",
      "batch=7/7, valLoss=0.022453567\n",
      "Epoch: 14/100\n",
      "batch=7/7, valLoss=0.022373518\n",
      "Epoch: 15/100\n",
      "batch=7/7, valLoss=0.022303478\n",
      "Epoch: 16/100\n",
      "batch=7/7, valLoss=0.022253445\n",
      "Epoch: 17/100\n",
      "batch=7/7, valLoss=0.022203415\n",
      "Epoch: 18/100\n",
      "batch=7/7, valLoss=0.022163389\n",
      "Epoch: 19/100\n",
      "batch=7/7, valLoss=0.022123366\n",
      "Epoch: 20/100\n",
      "batch=7/7, valLoss=0.022093344\n",
      "Epoch: 21/100\n",
      "batch=7/7, valLoss=0.022063325\n",
      "Epoch: 22/100\n",
      "batch=7/7, valLoss=0.022033306\n",
      "Epoch: 23/100\n",
      "batch=7/7, valLoss=0.022003289\n",
      "Epoch: 24/100\n",
      "batch=7/7, valLoss=0.021983273\n",
      "Epoch: 25/100\n",
      "batch=7/7, valLoss=0.021953258\n",
      "Epoch: 26/100\n",
      "batch=7/7, valLoss=0.021933243\n",
      "Epoch: 27/100\n",
      "batch=7/7, valLoss=0.021913230\n",
      "Epoch: 28/100\n",
      "batch=7/7, valLoss=0.021893217\n",
      "Epoch: 29/100\n",
      "batch=7/7, valLoss=0.021873204\n",
      "Epoch: 30/100\n",
      "batch=7/7, valLoss=0.021853193\n",
      "Epoch: 31/100\n",
      "batch=7/7, valLoss=0.021833182\n",
      "Epoch: 32/100\n",
      "batch=7/7, valLoss=0.021813171\n",
      "Epoch: 33/100\n",
      "batch=7/7, valLoss=0.021793161\n",
      "Epoch: 34/100\n",
      "batch=7/7, valLoss=0.021783151\n",
      "Epoch: 35/100\n",
      "batch=7/7, valLoss=0.021763142\n",
      "Epoch: 36/100\n",
      "batch=7/7, valLoss=0.021743133\n",
      "Epoch: 37/100\n",
      "batch=7/7, valLoss=0.021733124\n",
      "Epoch: 38/100\n",
      "batch=7/7, valLoss=0.021713116\n",
      "Epoch: 39/100\n",
      "batch=7/7, valLoss=0.021703108\n",
      "Epoch: 40/100\n",
      "batch=7/7, valLoss=0.021683100\n",
      "Epoch: 41/100\n",
      "batch=7/7, valLoss=0.021673093\n",
      "Epoch: 42/100\n",
      "batch=7/7, valLoss=0.021663086\n",
      "Epoch: 43/100\n",
      "batch=7/7, valLoss=0.021643079\n",
      "Epoch: 44/100\n",
      "batch=7/7, valLoss=0.021633073\n",
      "Epoch: 45/100\n",
      "batch=7/7, valLoss=0.021623066\n",
      "Epoch: 46/100\n",
      "batch=7/7, valLoss=0.021613060\n",
      "Epoch: 47/100\n",
      "batch=7/7, valLoss=0.021593054\n",
      "Epoch: 48/100\n",
      "batch=7/7, valLoss=0.021583048\n",
      "Epoch: 49/100\n",
      "batch=7/7, valLoss=0.021573043\n",
      "Epoch: 50/100\n",
      "batch=7/7, valLoss=0.021563038\n",
      "Epoch: 51/100\n",
      "batch=7/7, valLoss=0.021553032\n",
      "Epoch: 52/100\n",
      "batch=7/7, valLoss=0.021543027\n",
      "Epoch: 53/100\n",
      "batch=7/7, valLoss=0.021533022\n",
      "Epoch: 54/100\n",
      "batch=7/7, valLoss=0.021523018\n",
      "Epoch: 55/100\n",
      "batch=7/7, valLoss=0.021513013\n",
      "Epoch: 56/100\n",
      "batch=7/7, valLoss=0.021513009\n",
      "Epoch: 57/100\n",
      "batch=7/7, valLoss=0.021503004\n",
      "Epoch: 58/100\n",
      "batch=7/7, valLoss=0.021493000\n",
      "Epoch: 59/100\n",
      "batch=7/7, valLoss=0.021482996\n",
      "Epoch: 60/100\n",
      "batch=7/7, valLoss=0.021472992\n",
      "Epoch: 61/100\n",
      "batch=7/7, valLoss=0.021472988\n",
      "Epoch: 62/100\n",
      "batch=7/7, valLoss=0.021462985\n",
      "Epoch: 63/100\n",
      "batch=7/7, valLoss=0.021452981\n",
      "Epoch: 64/100\n",
      "batch=7/7, valLoss=0.021442978\n",
      "Epoch: 65/100\n",
      "batch=7/7, valLoss=0.021442974\n",
      "Epoch: 66/100\n",
      "batch=7/7, valLoss=0.021432971\n",
      "Epoch: 67/100\n",
      "batch=7/7, valLoss=0.021432968\n",
      "Epoch: 68/100\n",
      "batch=7/7, valLoss=0.021422964\n",
      "Epoch: 69/100\n",
      "batch=7/7, valLoss=0.021412961\n",
      "Epoch: 70/100\n",
      "batch=7/7, valLoss=0.021412958\n",
      "Epoch: 71/100\n",
      "batch=7/7, valLoss=0.021402956\n",
      "Epoch: 72/100\n",
      "batch=7/7, valLoss=0.021402953\n",
      "Epoch: 73/100\n",
      "batch=7/7, valLoss=0.021392950\n",
      "Epoch: 74/100\n",
      "batch=7/7, valLoss=0.021392947\n",
      "Epoch: 75/100\n",
      "batch=7/7, valLoss=0.021382945\n",
      "Epoch: 76/100\n",
      "batch=7/7, valLoss=0.021382942\n",
      "Epoch: 77/100\n",
      "batch=7/7, valLoss=0.021372940\n",
      "Epoch: 78/100\n",
      "batch=7/7, valLoss=0.021372938\n",
      "Epoch: 79/100\n",
      "batch=7/7, valLoss=0.021372935\n",
      "Epoch: 80/100\n",
      "batch=7/7, valLoss=0.021362933\n",
      "Epoch: 81/100\n",
      "batch=7/7, valLoss=0.021362931\n",
      "Epoch: 82/100\n",
      "batch=7/7, valLoss=0.021352929\n",
      "Epoch: 83/100\n",
      "batch=7/7, valLoss=0.021352927\n",
      "Epoch: 84/100\n",
      "batch=7/7, valLoss=0.021352925\n",
      "Epoch: 85/100\n",
      "batch=7/7, valLoss=0.021342923\n",
      "Epoch: 86/100\n",
      "batch=7/7, valLoss=0.021342921\n",
      "Epoch: 87/100\n",
      "batch=7/7, valLoss=0.021342919\n",
      "Epoch: 88/100\n",
      "batch=7/7, valLoss=0.021332917\n",
      "Epoch: 89/100\n",
      "batch=7/7, valLoss=0.021332916\n",
      "Epoch: 90/100\n",
      "batch=7/7, valLoss=0.021332914\n",
      "Epoch: 91/100\n",
      "batch=7/7, valLoss=0.021322912\n",
      "Epoch: 92/100\n",
      "batch=7/7, valLoss=0.021322911\n",
      "Epoch: 93/100\n",
      "batch=7/7, valLoss=0.021322909\n",
      "Epoch: 94/100\n",
      "batch=7/7, valLoss=0.021322908\n",
      "Epoch: 95/100\n",
      "batch=7/7, valLoss=0.021312906\n",
      "Epoch: 96/100\n",
      "batch=7/7, valLoss=0.021312905\n",
      "Epoch: 97/100\n",
      "batch=7/7, valLoss=0.021312903\n",
      "Epoch: 98/100\n",
      "batch=7/7, valLoss=0.021312902\n",
      "Epoch: 99/100\n",
      "batch=7/7, valLoss=0.021302901\n",
      "Epoch: 100/100\n",
      "batch=7/7, valLoss=0.021302899\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "output_dir = \".\"\n",
    "save_per_ep = 30\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "history = {\"trainLossL\":[], \"valLossL\":[]}\n",
    "for ep in range(epochs):\n",
    "    print(f\"Epoch: {ep+1}/{epochs}\")\n",
    "    # train\n",
    "    trainLoss= 0.\n",
    "    for i,(X,y) in enumerate(trainDataLoader):\n",
    "        optimizer.zero_grad()    # zero the parameter gradients\n",
    "        pred = model(X)          # f(x) and f'(x)\n",
    "        loss = myLoss(y,pred)    # compute loss\n",
    "        loss.backward()          # send loss to torch\n",
    "        optimizer.step()         # update model parameters by torch loss \n",
    "        trainLoss += loss.item() / len(trainDataset)\n",
    "        print(f\"\\rbatch={i+1}/{len(trainDataLoader)}, trainLoss={trainLoss:.5f}\", end=\"\")\n",
    "    history[\"trainLossL\"].append(trainLoss)\n",
    "    # save\n",
    "    if ep%save_per_ep==0 or ep==epochs-1:\n",
    "        torch.save({'model_state_dict':model.state_dict(),'epoch':ep,'loss':trainLoss}, f\"{output_dir}/ckpt-{ep}.pth\")\n",
    "    # validation\n",
    "    valLoss = 0.\n",
    "    for i,(X,y) in enumerate(valDataLoader):\n",
    "        with torch.no_grad():\n",
    "            pred = model(X)\n",
    "            loss = lossFunc(pred,y)\n",
    "            valLoss += loss.item() / len(valDataset)\n",
    "            print(f\"\\rbatch={i+1}/{len(valDataLoader)}, valLoss={valLoss:.5f}\", end=\"\")\n",
    "    history[\"valLossL\"].append(valLoss)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a06f73",
   "metadata": {},
   "source": [
    "### Training result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94e4a6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.figure()\n",
    "f.set_facecolor(\"orange\")\n",
    "plt.plot(history['trainLossL'])\n",
    "plt.plot(history['valLossL'])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"mse\")\n",
    "plt.legend(labels=['train','val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f768ea",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45068d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.2721 17.5889 0.9277\n",
      "-4.8279 -10.676 0.6787\n",
      "8.9721 8.9355 0.998\n",
      "6.0721 0.3412 0.6852\n",
      "7.2721 8.7502 0.9188\n",
      "15.0721 14.6483 0.9767\n",
      "7.3721 7.8355 0.9745\n",
      "-3.1279 -7.6526 0.7514\n",
      "6.9721 13.155 0.6603\n",
      "6.1721 4.8267 0.9261\n",
      "8.0721 10.9239 0.8433\n",
      "11.4721 15.0221 0.805\n",
      "19.6721 23.0781 0.8129\n",
      "1.2721 1.7097 0.976\n",
      "4.6721 5.4439 0.9576\n",
      "36.3721 26.2169 0.4421\n",
      "4.7721 2.6212 0.8818\n",
      "7.5721 8.032 0.9747\n",
      "1.9721 6.287 0.763\n",
      "8.0721 8.2327 0.9912\n",
      "4.9721 6.4967 0.9162\n",
      "15.0721 17.3732 0.8736\n",
      "6.2721 5.7394 0.9707\n",
      "13.8721 -1.2012 0.1719\n",
      "9.6721 8.02 0.9092\n",
      "6.5721 8.158 0.9129\n",
      "-0.5279 0.783 0.928\n",
      "36.3721 16.8068 -0.0749\n",
      "5.8721 4.7923 0.9407\n",
      "6.4721 7.093 0.9659\n",
      "9.0721 6.736 0.8717\n",
      "8.9721 11.1884 0.8782\n",
      "6.4721 4.3745 0.8848\n",
      "-1.5279 4.1307 0.6891\n",
      "2.9721 4.6124 0.9099\n",
      "6.6721 9.8298 0.8265\n",
      "36.3721 10.1888 -0.4384\n",
      "9.4721 3.2638 0.6589\n",
      "23.3721 17.6028 0.6831\n",
      "0.9721 4.9734 0.7802\n",
      "5.3721 7.3289 0.8925\n",
      "8.5721 10.19 0.9111\n",
      "4.8721 5.4774 0.9667\n",
      "10.1721 11.2035 0.9433\n",
      "9.4721 8.8104 0.9636\n",
      "5.7721 6.2128 0.9758\n",
      "0.6721 3.0081 0.8717\n",
      "-2.8279 -2.3232 0.9723\n",
      "10.0721 14.7216 0.7446\n",
      "7.0721 7.968 0.9508\n",
      "-6.1279 -0.1532 0.6718\n",
      "2.6721 -1.7163 0.7589\n",
      "-2.7279 1.5922 0.7627\n",
      "0.5721 3.771 0.8243\n",
      "5.7721 10.2381 0.7547\n",
      "3.1721 4.5666 0.9234\n",
      "11.3721 14.2585 0.8414\n",
      "15.9721 11.8147 0.7716\n",
      "5.4721 3.0615 0.8676\n",
      "-3.4279 3.0241 0.6455\n",
      "-0.3279 1.816 0.8822\n",
      "9.1721 13.9231 0.739\n",
      "6.7721 9.1174 0.8712\n",
      "2.4721 4.6124 0.8824\n",
      "7.1721 3.45 0.7955\n",
      "29.4721 23.3931 0.666\n",
      "32.3721 25.4863 0.6217\n",
      "4.3721 5.8783 0.9173\n",
      "36.3721 27.282 0.5006\n",
      "-4.9279 -4.5497 0.9792\n",
      "13.8721 11.0977 0.8476\n",
      "9.6721 12.4927 0.845\n",
      "17.8721 18.9134 0.9428\n",
      "5.4721 2.4792 0.8356\n",
      "10.7721 8.7669 0.8898\n",
      "-0.2279 2.7642 0.8356\n",
      "-5.5279 -8.5417 0.8344\n",
      "4.5721 4.7492 0.9903\n",
      "7.2721 7.4358 0.991\n",
      "8.4721 13.0518 0.7484\n",
      "19.4721 19.9209 0.9753\n",
      "8.7721 10.1963 0.9218\n",
      "14.7721 15.0515 0.9847\n",
      "3.8721 3.7456 0.9931\n",
      "16.1721 18.7873 0.8563\n",
      "34.6721 23.5371 0.3883\n",
      "5.5721 10.0597 0.7535\n",
      "20.1721 20.9822 0.9555\n",
      "18.0721 19.4292 0.9254\n",
      "5.8721 5.5479 0.9822\n",
      "15.9721 10.7543 0.7133\n",
      "30.1721 21.8398 0.5422\n",
      "-0.9279 3.7822 0.7412\n",
      "7.3721 7.6147 0.9867\n",
      "15.4721 16.3905 0.9495\n",
      "6.8721 6.8266 0.9975\n",
      "9.1721 15.0245 0.6785\n",
      "13.3721 18.0304 0.7441\n",
      "7.9721 11.5888 0.8013\n",
      "3.6721 2.7297 0.9482\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "model.eval()            # Turn off some layers such as dropout, batch normalization for model inference\n",
    "with torch.no_grad():   # Turn off gradient calculation\n",
    "    pass\n",
    "\"\"\"\n",
    "with torch.no_grad():\n",
    "    realL, predL = [], []\n",
    "    for X,y in valDataLoader:\n",
    "        realL += list( y.cpu().detach().numpy().reshape(-1) )\n",
    "        pred = model(X)\n",
    "        predL += list( pred.cpu().detach().numpy().reshape(-1) )\n",
    "        \n",
    "realL = list(map(lambda x:round(x*stds[13]+stds[13],4),realL))\n",
    "predL = list(map(lambda x:round(x*stds[13]+stds[13],4),predL))\n",
    "errL  = [ round(1-abs(pred-real)/(stds[13]*2),4) for real,pred in zip(realL,predL) ]\n",
    "for real,pred,err in zip(realL,predL,errL):\n",
    "    print(real,pred,err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0faaecb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8167"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(sum(errL)/len(errL),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8dd7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99522d64",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dfb0341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (dense1): Linear(in_features=13, out_features=64, bias=True)\n",
      "  (dense2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (dense3): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1  = nn.Linear(13, 64)\n",
    "        self.dense2  = nn.Linear(64, 64)\n",
    "        self.dense3  = nn.Linear(64, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "\n",
    "model = MyModel().to('cuda')\n",
    "print( model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "714be99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"./ckpt-99.pth\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50c261e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8091"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    realL, predL = [], []\n",
    "    for X,y in valDataLoader:\n",
    "        realL += list( y.cpu().detach().numpy().reshape(-1) )\n",
    "        pred = model(X)\n",
    "        predL += list( pred.cpu().detach().numpy().reshape(-1) )\n",
    "        \n",
    "realL = list(map(lambda x:round(x*stds[13]+stds[13],4),realL))\n",
    "predL = list(map(lambda x:round(x*stds[13]+stds[13],4),predL))\n",
    "errL  = [ round(1-abs(pred-real)/(stds[13]*2),4) for real,pred in zip(realL,predL) ]\n",
    "#for real,pred,err in zip(realL,predL,errL):\n",
    "#    print(real,pred,err)\n",
    "round(sum(errL)/len(errL),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ada95c",
   "metadata": {},
   "source": [
    "### More:\n",
    "+ modularization all processes\n",
    "+ specify the weight, then load it after initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724e61c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
